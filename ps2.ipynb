{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Krussel-Smith with Deep Equilibrium Nets\n",
    "*Simon Lebastard, 02/07/2023*\n",
    "\n",
    "## Krussel-Smith (1998) model\n",
    "In the KS'98 model, we look a flavour of the stochastic growth model with a continuum of households under partially uninsurable risk.\n",
    "\n",
    "**Demand side**\n",
    "$$V(c) = \\mathrm{E}_0\\Big[\\sum_{t=0}^{\\infty}{\\beta^t U(c_t)}\\Big]$$\n",
    "with\n",
    "$$U(c) = \\lim_{\\nu \\to \\sigma}{\\frac{c^{1-\\nu} - 1}{1 - \\nu}}$$\n",
    "\n",
    "Agents are each endowed with $\\epsilon \\tilde{l}$ units of labor per period, where $\\epsilon$ is a first-order Markov chain. (In K&S'98, $\\epsilon$ can only take two values: 0 and 1, representing unemployed and employed idiosyncratic states, respectively).\n",
    "As a very large number of agents is consided, and by assumed independence of the idiosyncratic shocks, K&S'98 assume that the total number of employed and unemployed people remain constant over time. That is, there is no aggregate fluctuations of jobs supply.\n",
    "\n",
    "Idiosyncratic endogenous state: $k$ holding of capital\n",
    "Idiosyncratic exogenous state: $\\epsilon$ at the individual level\n",
    "$\\Gamma$ the joint distribution of idiosyncratic states $(k,\\epsilon)$\n",
    "\n",
    "Given the aggregate states (see $z$ defined below), the consumer's optimization problem is:\n",
    "$$v(k,\\epsilon;\\Gamma,z) = \\max_{c,k'}{ \\Big\\{ U(c) + \\beta\\mathrm{E}\\Big[v(k',\\epsilon';\\Gamma',z') \\mid z,\\epsilon \\Big] \\Big\\} } $$\n",
    "under budget constraint, rational expectations wrt law of motion and non-negative capital holding.\n",
    "\n",
    "The budget constraint writes:\n",
    "$$c+k' = r(\\hat{k},\\hat{l},z)k + w(\\hat{k},\\hat{l},z)\\tilde{l}\\epsilon + (1-\\delta)k$$\n",
    "\n",
    "**Supply side**\n",
    "A single-type good is produced using two factors of production: labor $l$ and capital $k$.\n",
    "The good is produced according to a Cobb-Douglas production function:\n",
    "$$y = zk^{\\alpha}l^{1-\\alpha}, \\quad \\alpha \\in [0,1]$$\n",
    "The TFP is stochastic and coresponds to the source of aggregate risk. In K&S'98, two aggregate states are considered: $(z_b, z_g)$.\n",
    "Again, $z$ follows a first-order Markov chain.\n",
    "\n",
    "We assume the production market to be competitive, such that wages $w$ and rental rates $r$, both functions of aggregate states, are respectively determined by:\n",
    "$$w(\\hat{k},\\hat{l},z) = (1 - \\alpha)z(\\frac{\\hat{k}}{\\hat{l}})^\\alpha$$\n",
    "$$r(\\hat{k},\\hat{l},z) = \\alpha z(\\frac{\\hat{k}}{\\hat{l}})^{\\alpha-1}$$\n",
    "\n",
    "Here we assume that as the population of households is infinitely large, the share of unemployed remains constant. Moreover, here consumers have no disutility from labor, implying that the labor supply at each period is constant at $L_s = N*\\mathrm{E}\\big[\\epsilon\\big]$.\n",
    "We have the market clearing condition for the capital/cons good: $$\\int{(c(k,\\epsilon;\\Gamma,z) + k'(k,\\epsilon;\\Gamma,z))dF(\\Gamma)} = (1-\\delta)\\int{k dF(\\Gamma)} + z\\int{k dF(\\Gamma)}^{\\alpha}L_s^{1-\\alpha}$$\n",
    "\n",
    "For both Markov chains, we assume the economy is already running at the stationary distribution.\n",
    "\n",
    "**Law of motion**\n",
    "$$\\Gamma' = H(\\Gamma,z,z')$$\n",
    "\n",
    "\n",
    "### Formulating the problem for solving with DEN\n",
    "Here we will consider two \"implicit\" policy functions for which we solve:\n",
    "- Next-period capital $k'(k,\\epsilon;\\Gamma,z)$\n",
    "- The Lagrange multiplier on the next-period capital non-negativity constraint: $\\mu_k(k,\\epsilon;\\Gamma,z)$\n",
    "- The Lagrange multiplier on the positivity of current-period consumption, ie of the residual of the budget constraint: $\\mu_c(k,\\epsilon;\\Gamma,z)$\n",
    "Implicitly, we also have as a current-period consumption $c(k,\\epsilon;\\Gamma,z)$ as a policy function. Following Azinovic et al, however, we use the consumer's budget constraint to compute the consumption at each period in time. As the utility function we're working with is locally nonsatiated, the consumer will bind it's budget constraint at each period.\n",
    "\n",
    "As in Azinovic et al, we simulate $N$ agents, and index $i \\in [1,...,N]$.\n",
    "\n",
    "#### Idiosyncratic error terms\n",
    "The Euler equation can be obtained by taking the FOC of the consumer's objective function with respect to next-period capital:\n",
    "$$1 = \\beta(1-\\delta)\\mathrm{E}\\Big[\\Big(\\frac{c(k,\\epsilon;\\Gamma,z)}{c(k',\\epsilon';\\Gamma',z')}\\Big)^{\\nu} \\mid z,\\epsilon\\Big] + \\mu(k,\\epsilon;\\Gamma,z)c(k,\\epsilon;\\Gamma,z)^{\\nu}$$\n",
    "\n",
    "Based on that, we defined the Euler error as:\n",
    "$$e_{EE}(k,\\epsilon,\\Gamma,z) \\equiv 1 - \\beta(1-\\delta)\\mathrm{E}\\Big[\\Big(\\frac{c(k,\\epsilon;\\Gamma,z)}{c(k',\\epsilon';\\Gamma',z')}\\Big)^{\\nu} \\mid z,\\epsilon\\Big] + \\mu(k,\\epsilon;\\Gamma,z)c(k,\\epsilon;\\Gamma,z)^{\\nu}$$\n",
    "and\n",
    "$$e_{EE,i} \\equiv e_{EE}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "\n",
    "We define the error on the complementary-slackness condition on k as:\n",
    "$$e_{CS_k}(k,\\epsilon,\\Gamma,z) \\equiv \\mu(k,\\epsilon;\\Gamma,z)k'(k,\\epsilon;\\Gamma,z)$$\n",
    "and\n",
    "$$e_{CS_k,i} \\equiv e_{CS_k}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "\n",
    "We define the error on the complementary-slackness condition on c as:\n",
    "$$e_{CS_c}(k,\\epsilon,\\Gamma,z) \\equiv \\mu(k,\\epsilon;\\Gamma,z)k'(k,\\epsilon;\\Gamma,z)$$\n",
    "and\n",
    "$$e_{CS_c,i} \\equiv e_{CS_c}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "\n",
    "#### Aggregate error term\n",
    "At each period, we compute the aggregate $K \\equiv \\sum_{i=1}^{N}{k_i}$\n",
    "\n",
    "One way to proceed could be to define an error based on the market clearing condition on capital. Instead, we will enforce consumption to satisfy the market clearing condition at each period. Note that in doing so, we could still need to enforce that consumption is positive. Instead of enforcing a new constraint on a Lagrangian multiplier associated with consumption, I compute the error on MC by constraining consumption to be positive in the error, by using a transformation of the error that satisfies:\n",
    "$$\\lim_{c \\downarrow 0}{e_{MC}(c)} = \\infty$$\n",
    "This should prevent consumption from ever being non-positive.\n",
    "\n",
    "We define the error on the market clearing condition as:\n",
    "$$e_{MC} \\equiv \\sum_{i=1}^{N}{\\Big[c(k_i,\\epsilon_i;\\Gamma,z) + k'(k_i,\\epsilon_i;\\Gamma,z)\\Big]} - zK^{\\alpha}(Nu)^{1-\\alpha} - (1-\\delta)K$$\n",
    "\n",
    "#### Defining the loss function\n",
    "On a batch $\\mathcal{D}_{train}$, the loss function is defined as:\n",
    "$$l(\\theta) \\equiv \\frac{1}{\\mid\\mathcal{D}_{train}\\mid} \\sum_{x \\in \\mathcal{D}_{train}}{\\frac{1}{N-1}\\sum_{i=1}^{N}{\\Big(e_{EE,i}^2 + e_{CS_k,i}^2 + e_{CS_c,i}^2\\Big)} + e_{MC}^2}$$\n",
    "\n",
    "**Note: alternative implementation**<br>\n",
    "Instead of having a policy variable for the Lagrange multiplier on the positivity of next-period capital, we could have a transformation function on  next-period capital that ensures it remains non-negative at all times. I will implement this alternative method and compare results.\n",
    "\n",
    "#### Defining network dimensions\n",
    "As we make consumption implicit, we have the following dimensions:\n",
    "- $2N+1$ scalar inputs: $(z, \\big\\{(k_i,\\epsilon_i)\\big\\}_{i \\in [1..N]})$\n",
    "- $4N$ scalar outputs: ${k_i', c_i, \\mu_{k,i}, \\mu_{c,i}}_{i \\in [1..N]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "class Vector: pass\n",
    "\n",
    "# Set the seed for replicable results\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "#tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = num_agents = 1000\n",
    "num_episodes = 5000 \n",
    "len_episodes = 1000\n",
    "epochs_per_episode = 20\n",
    "minibatch_size = 512\n",
    "num_minibatches = int(len_episodes / minibatch_size)\n",
    "lr = 0.00001\n",
    "\n",
    "# Neural network architecture parameters\n",
    "num_input_nodes = 2*N + 1  # Dimension of extended state space (8 aggregate quantities and 4 distributions)\n",
    "num_output_nodes = 2*N  # Output dimension (capital holding for each agent. Agent 1 is born without capital (k^1=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 09:55:18.044050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import binomial, multinomial\n",
    "\n",
    "# Shocks structure\n",
    "Z = np.array([0.9, 1.1])\n",
    "z_l = Z[0]\n",
    "z_h = Z[1]\n",
    "P_z = np.array([[0.9, 0.1], [0.1, 0.9]])\n",
    "def draw_z(z):\n",
    "    z_id = int(z==z_h)\n",
    "    zp_id = multinomial(1,P_z[z_id,:])\n",
    "    return Z[zp_id]\n",
    "\n",
    "E = np.array([0, 1])\n",
    "ε_l = E[0]\n",
    "ε_h = E[1]\n",
    "P_ε = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "def draw_ε(size):\n",
    "    return binomial(1,0.5,size)\n",
    "\n",
    "# Other constants\n",
    "α = tf.constant(0.3)\n",
    "β = tf.constant(0.7)\n",
    "δ = tf.constant(0.1)\n",
    "γ = tf.constant(2.0)\n",
    "L = N*E.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firm(K,z):\n",
    "    prod = z*tf.pow(K, α)*tf.pow(L, 1-α)\n",
    "    r = z*α*tf.pow(K, α-1)*tf.pow(L, 1-α)\n",
    "    w = z*(1-α)*tf.pow(K, α)*tf.pow(L, -α)\n",
    "    return prod, r, w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - Architecture\n",
    "\n",
    "### Compact network approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "n_aggr_repr = 8\n",
    "\n",
    "## AGGREGATE REPRESENTATION UNITS\n",
    "# Common network processes distribution-relevant information\n",
    "x_aggr = Input(shape = (2,))\n",
    "xn_aggr = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,)(x_aggr)\n",
    "aggr_1 = Dense(4*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer)(xn_aggr)\n",
    "aggr_2 = Dense(4*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer)(aggr_1)\n",
    "aggr_3 = Dense(2*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer)(aggr_2)\n",
    "aggr_4 = Dense(n_aggr_repr, activation = 'tanh', kernel_initializer=initializer)(aggr_3)\n",
    "\n",
    "## POLICY UNITS\n",
    "# Agent-specific policy units\n",
    "x_idio = Input(shape = (2,))\n",
    "interp_c_h_1 = Dense(32, input_dim=2+n_aggr_repr, activation = 'tanh', kernel_initializer=initializer)(tf.concat(values=(x_idio,aggr_4),axis=1))\n",
    "interp_c_h_2 = Dense(32, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_1)\n",
    "policy = Dense(4, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_2)\n",
    "\n",
    "nn1 = Model(inputs = (x_aggr,x_idio), outputs= policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute-force MC-Distribution-processing neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aggr_reprb = 8\n",
    "\n",
    "## AGGREGATE REPRESENTATION UNITS\n",
    "# Common network processes distribution-relevant information\n",
    "x_aggrb = Input(shape = (2,))\n",
    "xn_aggrb = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,)(x_aggr)\n",
    "aggr_1b = Dense(4*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(xn_aggr)\n",
    "aggr_2b = Dense(4*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_1)\n",
    "aggr_3b = Dense(2*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_2)\n",
    "aggr_4b = Dense(n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_3)\n",
    "\n",
    "## POLICY UNITS\n",
    "# Agent-specific policy units\n",
    "x_idiob = Input(shape = (2*N,))\n",
    "interp_c_h_1b = Dense(32, input_dim=2*N+n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(tf.concat(values=(x_idiob,aggr_4b),axis=1))\n",
    "interp_c_h_2b = Dense(32, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_1b)\n",
    "policyb = Dense(2*N, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_2b)\n",
    "\n",
    "nn2 = Model(inputs = tf.concat(values=(x_aggrb,x_idiob)), outputs= policyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, nn: Model):\n",
    "        self.nn = nn\n",
    "        \n",
    "def forward(nn:Model, k:np.array, ε:np.array, z:float):\n",
    "    N = k.shape[0]\n",
    "    kp = np.full_like(k)\n",
    "    mup = np.zeros_like(k)\n",
    "    K = k.sum()\n",
    "    for agent_id in range(N):\n",
    "        pol = nn((z,K,k[agent_id], ε[agent_id]))\n",
    "        kp[agent_id] = pol[0]\n",
    "        mup[agent_id] = pol[1]\n",
    "    return kp, mup\n",
    "\n",
    "def budget_residual(k: np.array, c: np.array, ε:int, kp: np.array, r:float, w:float):\n",
    "    return w*ε + (1+r-δ)*k - kp - c\n",
    "\n",
    "def FB(a:float, b:float):\n",
    "    return a + b - tf.sqrt(tf.pow(a,2) + tf.pow(b,2))\n",
    "\n",
    "def residuals(nn:Model, k:np.array, ε:np.array, z:float):\n",
    "    N = k.shape[0]\n",
    "    K = tf.math.reduce_sum(k)\n",
    "    Y,r,w = firm(K,z)\n",
    "\n",
    "    # 1st forward pass\n",
    "    kp, mup, c, lambdap = forward(nn, k, ε, z)\n",
    "    C = tf.math.reduce_sum(c)\n",
    "    Kp = tf.math.reduce_sum(kp)\n",
    "    BUDGET_RES = budget_residual(k, c, ε, kp, r, w)\n",
    "    CSK_RES = mup*kp\n",
    "    CSC_RES = c*lambdap\n",
    "\n",
    "    # For each possible value of next-period exogenous states, compute the next-period policy\n",
    "    kpp = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    Kpp = np.zeros((2,2))\n",
    "    mupp = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    lambdapp = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    cp = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    Cp = np.zeros((2,2))\n",
    "    ee_comp = np.zeros((2,2))\n",
    "    BUDGET_RES_COND = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    CSK_RES_COND = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    CSC_RES_COND = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "    MC_RES_COND = np.zeros((2,2)) # ToDo: change size, there will be one scalar error term per agent\n",
    "\n",
    "    for zp_id, zp in enumerate(Z):\n",
    "        Yp,rp,wp = firm(Kp,zp)\n",
    "        for εp_id, εp in enumerate(E):\n",
    "            ypp = forward(nn, kp, εp, zp)\n",
    "            kpp[zp_id,εp_id] = ypp[0]\n",
    "            mupp[zp_id,εp_id] = ypp[1]\n",
    "            cp[zp_id,εp_id] = ypp[2]\n",
    "            lambdapp[zp_id,εp_id] = ypp[3]\n",
    "            ee_comp[zp_id,εp_id] = tf.pow(c/cp[zp_id,εp_id],nu)\n",
    "            BUDGET_RES_COND[zp_id,εp_id] = budget_residual(kp, ypp[2], εp, ypp[0], rp, wp)\n",
    "            CSK_RES_COND[zp_id,εp_id] = mupp[zp_id,εp_id]*kpp[zp_id,εp_id]\n",
    "            CSC_RES_COND[zp_id,εp_id] = cp[zp_id,εp_id]*lambdapp[zp_id,εp_id]\n",
    "\n",
    "            Kpp[zp_id,εp_id] = tf.math.reduce_sum(kpp[zp_id,εp_id])\n",
    "            Cp[zp_id,εp_id] = tf.math.reduce_sum(cp[zp_id,εp_id])\n",
    "            MC_RES_COND[zp_id,εp_id] = Cp[zp_id,εp_id] + Kpp[zp_id,εp_id] - (1-δ)*Kp - Yp\n",
    "\n",
    "    EE_RES = 1 - β*(1-δ)*tf.math.reduce_mean(tf.tensordot(P_z[int(z==z_h)],ee_comp))\n",
    "    MC_RES = C + Kp - (1-δ)*K - Y\n",
    "    return BUDGET_RES, CSK_RES, CSC_RES, MC_RES\n",
    "\n",
    "def J(nn: Model, z, k, ε, mb_size):\n",
    "    ERR = 0\n",
    "    for per_id in range(mb_size):\n",
    "        y = forward(nn, k, ε, z)\n",
    "        BUDGET_RES, CSK_RES, CSC_RES, MC_RES = residuals(nn, k, ε, z)\n",
    "        ERR += (1./mb_size)*tf.math.reduce_mean(BUDGET_RES*BUDGET_RES + CSK_RES*CSK_RES + CSC_RES*CSC_RES) + MC_RES*MC_RES\n",
    "        k = y[O]\n",
    "        ε = draw_ε(N)\n",
    "        z = draw_z(z)\n",
    "    return ERR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dynamic Programming & DL",
   "language": "python",
   "name": "dynprog_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
