{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Krussel-Smith with Deep Equilibrium Nets\n",
    "*Simon Lebastard, 02/07/2023*\n",
    "\n",
    "## Krussel-Smith (1998) model\n",
    "In the KS'98 model, we look a flavour of the stochastic growth model with a continuum of households under partially uninsurable risk.\n",
    "\n",
    "**Demand side**\n",
    "$$V(c) = \\mathrm{E}_0\\Big[\\sum_{t=0}^{\\infty}{\\beta^t U(c_t)}\\Big]$$\n",
    "with\n",
    "$$U(c) = \\lim_{\\nu \\to \\sigma}{\\frac{c^{1-\\nu} - 1}{1 - \\nu}}$$\n",
    "\n",
    "Agents are each endowed with $\\epsilon \\tilde{l}$ units of labor per period, where $\\epsilon$ is a first-order Markov chain. (In K&S'98, $\\epsilon$ can only take two values: 0 and 1, representing unemployed and employed idiosyncratic states, respectively).\n",
    "As a very large number of agents is consided, and by assumed independence of the idiosyncratic shocks, K&S'98 assume that the total number of employed and unemployed people remain constant over time. That is, there is no aggregate fluctuations of jobs supply.\n",
    "\n",
    "Idiosyncratic endogenous state: $k$ holding of capital\n",
    "Idiosyncratic exogenous state: $\\epsilon$ at the individual level\n",
    "$\\Gamma$ the joint distribution of idiosyncratic states $(k,\\epsilon)$\n",
    "\n",
    "Given the aggregate states (see $z$ defined below), the consumer's optimization problem is:\n",
    "$$v(k,\\epsilon;\\Gamma,z) = \\max_{c,k'}{ \\Big\\{ U(c) + \\beta\\mathrm{E}\\Big[v(k',\\epsilon';\\Gamma',z') \\mid z,\\epsilon \\Big] \\Big\\} } $$\n",
    "under budget constraint, rational expectations wrt law of motion and non-negative capital holding.\n",
    "\n",
    "The budget constraint writes:\n",
    "$$c+k' = r(\\hat{k},\\hat{l},z)k + w(\\hat{k},\\hat{l},z)\\tilde{l}\\epsilon + (1-\\delta)k$$\n",
    "\n",
    "**Supply side**\n",
    "A single-type good is produced using two factors of production: labor $l$ and capital $k$.\n",
    "The good is produced according to a Cobb-Douglas production function:\n",
    "$$y = zk^{\\alpha}l^{1-\\alpha}, \\quad \\alpha \\in [0,1]$$\n",
    "The TFP is stochastic and coresponds to the source of aggregate risk. In K&S'98, two aggregate states are considered: $(z_b, z_g)$.\n",
    "Again, $z$ follows a first-order Markov chain.\n",
    "\n",
    "We assume the production market to be competitive, such that wages $w$ and rental rates $r$, both functions of aggregate states, are respectively determined by:\n",
    "$$w(\\hat{k},\\hat{l},z) = (1 - \\alpha)z(\\frac{\\hat{k}}{\\hat{l}})^\\alpha$$\n",
    "$$r(\\hat{k},\\hat{l},z) = \\alpha z(\\frac{\\hat{k}}{\\hat{l}})^{\\alpha-1}$$\n",
    "\n",
    "Here we assume that as the population of households is infinitely large, the share of unemployed remains constant. Moreover, here consumers have no disutility from labor, implying that the labor supply at each period is constant at $L_s = N*\\mathrm{E}\\big[\\epsilon\\big]$.\n",
    "We have the market clearing condition for the capital/cons good: $$\\int{(c(k,\\epsilon;\\Gamma,z) + k'(k,\\epsilon;\\Gamma,z))dF(\\Gamma)} = (1-\\delta)\\int{k dF(\\Gamma)} + z\\int{k dF(\\Gamma)}^{\\alpha}L_s^{1-\\alpha}$$\n",
    "\n",
    "For both Markov chains, we assume the economy is already running at the stationary distribution.\n",
    "\n",
    "**Law of motion**\n",
    "$$\\Gamma' = H(\\Gamma,z,z')$$\n",
    "\n",
    "\n",
    "### Formulating the problem for solving with DEN\n",
    "Here we will consider two \"implicit\" policy functions for which we solve:\n",
    "- Next-period capital $k'(k,\\epsilon;\\Gamma,z)$\n",
    "- The Lagrange multiplier on the next-period capital non-negativity constraint: $\\mu_k(k,\\epsilon;\\Gamma,z)$\n",
    "- The Lagrange multiplier on the positivity of current-period consumption, ie of the residual of the budget constraint: $\\mu_c(k,\\epsilon;\\Gamma,z)$\n",
    "\n",
    "As in Azinovic et al, we simulate $N$ agents, and index $i \\in [1,...,N]$.\n",
    "\n",
    "#### Idiosyncratic error terms\n",
    "The Euler equation can be obtained by taking the FOC of the consumer's objective function with respect to next-period capital:\n",
    "$$1 = \\beta(1-\\delta)\\mathrm{E}\\Big[\\Big(\\frac{c(k,\\epsilon;\\Gamma,z)}{c(k',\\epsilon';\\Gamma',z')}\\Big)^{\\nu} \\mid z,\\epsilon\\Big] - \\big(\\mu_c(k,\\epsilon;\\Gamma,z) - \\mu_k(k,\\epsilon;\\Gamma,z) \\big)c(k,\\epsilon;\\Gamma,z)^{\\nu}$$\n",
    "\n",
    "Based on that, we defined the Euler error as:\n",
    "$$e_{EE}(k,\\epsilon,\\Gamma,z) \\equiv \\bigg[\\beta(1-\\delta)\\mathrm{E}\\Big[\\Big(\\frac{c(k,\\epsilon;\\Gamma,z)}{c(k',\\epsilon';\\Gamma',z')}\\Big)^{\\nu} \\mid z,\\epsilon\\Big] - \\big(\\mu_c(k,\\epsilon;\\Gamma,z) - \\mu_k(k,\\epsilon;\\Gamma,z) \\big)\\bigg]^{-\\frac{1}{\\nu}} - 1$$\n",
    "and\n",
    "$$e_{EE,i} \\equiv e_{EE}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "Here we want to train the model to capture binding constraints by itself. Note that in practice, during training we may end up with negative consumptions (that will be penalized), such that ratio $\\frac{c(k,\\epsilon;\\Gamma,z)}{c(k',\\epsilon';\\Gamma',z')}^\\nu$ may not be defined for $\\nu \\in \\mathbb{R}$.\n",
    "To solve this issue, I use RELU activation in the last two layers of the network, to enforce $c(k,\\epsilon;\\Gamma,z), k'(k,\\epsilon;\\Gamma,z), \\mu_c(k,\\epsilon;\\Gamma,z), \\mu_k(k,\\epsilon;\\Gamma,z)$ to be non-negative for all states.\n",
    "\n",
    "We define the error on the complementary-slackness condition on k as:\n",
    "$$e_{CS_k}(k,\\epsilon,\\Gamma,z) \\equiv \\frac{\\mu_k(k,\\epsilon;\\Gamma,z)}{U'(\\bar{c})} \\frac{k'(k,\\epsilon;\\Gamma,z)}{\\bar{k}}$$\n",
    "and\n",
    "$$e_{CS_k,i} \\equiv e_{CS_k}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "\n",
    "We define the error on the complementary-slackness condition on c as:\n",
    "$$e_{CS_c}(k,\\epsilon,\\Gamma,z) \\equiv \\frac{\\mu_c(k,\\epsilon;\\Gamma,z)}{U'(\\bar{c})} \\frac{c(k,\\epsilon;\\Gamma,z)}{\\bar{c}}$$\n",
    "and\n",
    "$$e_{CS_c,i} \\equiv e_{CS_c}(k_i,\\epsilon_i,\\Gamma,z)$$\n",
    "\n",
    "The agent's budget constraint is:\n",
    "$$e_{BC}(k,\\epsilon,\\Gamma,z) \\equiv \\frac{1}{\\hat{c}+\\hat{k}}\\bigg[ c + k' - \\big( 1 + r(\\hat{k}, \\hat{l}, z) - \\delta \\big)k - w(\\hat{k}, \\hat{l}, z)\\tilde{l}\\epsilon \\bigg] $$\n",
    "\n",
    "#### Aggregate error term\n",
    "At each period, we compute the aggregate $K \\equiv \\sum_{i=1}^{N}{k_i}$\n",
    "\n",
    "One way to proceed could be to define an error based on the market clearing condition on capital. Instead, we will enforce consumption to satisfy the market clearing condition at each period. Note that in doing so, we could still need to enforce that consumption is positive. Instead of enforcing a new constraint on a Lagrangian multiplier associated with consumption, I compute the error on MC by constraining consumption to be positive in the error, by using a transformation of the error that satisfies:\n",
    "$$\\lim_{c \\downarrow 0}{e_{MC}(c)} = \\infty$$\n",
    "This should prevent consumption from ever being non-positive.\n",
    "\n",
    "We define the error on the market clearing condition as:\n",
    "$$e_{MC} \\equiv \\sum_{i=1}^{N}{\\Big[c(k_i,\\epsilon_i;\\Gamma,z) + k'(k_i,\\epsilon_i;\\Gamma,z)\\Big]} - zK^{\\alpha}(Nu)^{1-\\alpha} - (1-\\delta)K$$\n",
    "\n",
    "We also define the error on the aggregate law of motion as:\n",
    "$$e_{LM} \\equiv $$\n",
    "\n",
    "#### Defining the loss function\n",
    "On a batch $\\mathcal{D}_{train}$, the loss function is defined as:\n",
    "$$l(\\theta) \\equiv \\frac{1}{\\mid\\mathcal{D}_{train}\\mid} \\sum_{x \\in \\mathcal{D}_{train}}{\\frac{1}{N-1}\\sum_{i=1}^{N}{\\Big(e_{EE,i}^2 + e_{CS_k,i}^2 + e_{CS_c,i}^2\\Big)} + e_{MC}^2}$$\n",
    "\n",
    "**Note: alternative implementation**<br>\n",
    "Instead of having a policy variable for the Lagrange multiplier on the positivity of next-period capital, we could have a transformation function on  next-period capital that ensures it remains non-negative at all times. I will implement this alternative method and compare results.\n",
    "\n",
    "#### Defining network dimensions\n",
    "As we make consumption implicit, we have the following dimensions:\n",
    "- $2N+1$ scalar inputs: $(z, \\big\\{(k_i,\\epsilon_i)\\big\\}_{i \\in [1..N]})$\n",
    "- $4N$ scalar outputs: ${k_i', c_i, \\mu_{k,i}, \\mu_{c,i}}_{i \\in [1..N]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 16:54:05.533857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import * #Input, Dense, BatchNormalization\n",
    "from tensorflow import Tensor\n",
    "\n",
    "# Set the seed for replicable results\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "#tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firm(K:Tensor, z:Tensor):\n",
    "    prod = z*tf.pow(K, α)*tf.pow(L, 1-α)\n",
    "    r = z*α*tf.pow(K, α-1)*tf.pow(L, 1-α)\n",
    "    w = z*(1-α)*tf.pow(K, α)*tf.pow(L, -α)\n",
    "    return prod, r, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 16:54:10.102653: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.random import stateless_binomial\n",
    "\n",
    "# Shocks structure\n",
    "Z = tf.constant([0.9, 1.1], dtype=tf.float32)\n",
    "z_l = Z[0]\n",
    "z_h = Z[1]\n",
    "P_z = tf.constant([[0.9, 0.1], [0.1, 0.9]], dtype=tf.float32)\n",
    "def draw_z(z):\n",
    "    z_id = int(z==z_h)\n",
    "    zp_id = stateless_binomial(shape=[1], seed=[123, 456], counts=[1.], probs=[P_z[z_id,1]])[0]\n",
    "    return Z[zp_id]\n",
    "\n",
    "E = tf.constant([0, 1], dtype=tf.float32)\n",
    "eps_l = E[0]\n",
    "eps_h = E[1]\n",
    "P_eps = tf.constant([[0.5, 0.5], [0.5, 0.5]], dtype=tf.float32)\n",
    "def draw_eps(N: int):\n",
    "    return stateless_binomial(\n",
    "        shape=[N,],\n",
    "        seed=[123, 456],\n",
    "        counts=1,\n",
    "        probs=0.5,\n",
    "        output_dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "# Other constants\n",
    "α = tf.constant(0.3, dtype=tf.float32)\n",
    "β = tf.constant(0.7, dtype=tf.float32)\n",
    "δ = tf.constant(0.1, dtype=tf.float32)\n",
    "γ = tf.constant(2.0, dtype=tf.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - Architecture\n",
    "\n",
    "The following is a specialization class of Keras' Model, with a custom training step with gradient taping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def budget_residual(k: Tensor, c: Tensor, eps:Tensor, kp: Tensor, r:float, w:float):\n",
    "    return w*eps + (1+r-δ)*k - kp - c\n",
    "\n",
    "@tf.function\n",
    "def FB(a:float, b:float):\n",
    "    return a + b - tf.sqrt(tf.pow(a,2) + tf.pow(b,2))\n",
    "\n",
    "class DENModel(Model):\n",
    "\n",
    "    @tf.function\n",
    "    def __init__(self, inputs, *args, **kwargs):\n",
    "        self.N = inputs[0].shape[1] - 1\n",
    "        super().__init__(inputs, *args, **kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def initialize_k(self):\n",
    "        k_ss = 2.\n",
    "        return tf.Variable(tf.random.uniform(shape=[self.N,], minval=0.8*k_ss, maxval=1.2*k_ss))\n",
    "\n",
    "    @tf.function\n",
    "    def _forward_DEPRECATED(self, z:Tensor, k:Tensor, eps:Tensor, training:bool=False):\n",
    "        kp = tf.Variable(tf.zeros_like(k))\n",
    "        mup = tf.Variable(tf.zeros_like(k))\n",
    "        c = tf.Variable(tf.zeros_like(k))\n",
    "        lambdap = tf.Variable(tf.zeros_like(k))\n",
    "\n",
    "        x_aggr = tf.concat([z[None],k],axis=0)\n",
    "        x_aggr = tf.reshape(x_aggr, shape=[1,-1])\n",
    "        for agent_id in range(self.N):\n",
    "            x_idio = tf.concat([k[agent_id][None], eps[agent_id][None]], axis=0)\n",
    "            x_idio = tf.reshape(x_idio, shape=[1,-1])\n",
    "            pol = self(inputs=(x_aggr, x_idio), training=training)\n",
    "            kp[agent_id].assign(pol[0,0])\n",
    "            mup[agent_id].assign(pol[0,1])\n",
    "            c[agent_id].assign(pol[0,2])\n",
    "            lambdap[agent_id].assign(pol[0,3])\n",
    "        return kp, mup, c, lambdap\n",
    "\n",
    "    @tf.function\n",
    "    def forward(self, z:Tensor, k:Tensor, eps:Tensor, training:bool=False):\n",
    "        x_aggr = tf.concat([z[None],k],axis=0)\n",
    "        x_aggr = tf.tile(tf.reshape(x_aggr, shape=[1,-1]), tf.constant([self.N,1], tf.int32))\n",
    "        \n",
    "        x_idio = tf.concat([tf.reshape(k,[-1,1]),tf.reshape(eps,[-1,1])],axis=1)\n",
    "        y = self(inputs=(x_aggr, x_idio), training=training)\n",
    "        return y\n",
    "\n",
    "    @tf.function\n",
    "    def residuals(self, z:Tensor, k:Tensor, eps:Tensor):\n",
    "        K = tf.math.reduce_sum(k)\n",
    "        if K<0:\n",
    "            print(\"K: NEGATIVE AGGREGATE CAPITAL DESPITE RELU!!\")\n",
    "        Y,r,w = firm(K,z)\n",
    "        #print(\"CURRENT-PERIOD AGGREGATE CAPITAL\")\n",
    "        #print(K)\n",
    "        #print(\"CURRENT-PERIOD PRODUCTION, ROC, WAGE\")\n",
    "        #print(Y,r,w)\n",
    "\n",
    "        # 1st forward pass\n",
    "        yp = self.forward(z, k, eps, training=True)\n",
    "        kp = yp[:,0]\n",
    "        mup = yp[:,1]\n",
    "        c = yp[:,2]\n",
    "        lambdap = yp[:,3]\n",
    "        C = tf.math.reduce_sum(c)\n",
    "        Kp = tf.math.reduce_sum(kp)\n",
    "        if Kp<0:\n",
    "            print(\"Kp: NEGATIVE AGGREGATE CAPITAL DESPITE RELU!!\")\n",
    "        BUDGET_RES = budget_residual(k, c, eps, kp, r, w)\n",
    "        CSK_RES = mup*kp\n",
    "        CSC_RES = c*lambdap\n",
    "\n",
    "        # For each possible value of next-period exogenous states, compute the next-period policy\n",
    "        kpp = tf.Variable(tf.zeros((self.N,2)))\n",
    "        Kpp = tf.Variable(tf.zeros((2,)))\n",
    "        mupp = tf.Variable(tf.zeros((self.N,2)))\n",
    "        lambdapp = tf.Variable(tf.zeros((self.N,2)))\n",
    "        cp = tf.Variable(tf.zeros((self.N,2)))\n",
    "        Cp = tf.Variable(tf.zeros((2,)))\n",
    "        ee_comp = tf.Variable(tf.zeros((self.N,2)))\n",
    "        # BUDGET_RES_COND = np.zeros((N,2))\n",
    "        # CSK_RES_COND = np.zeros((N,2))\n",
    "        # CSC_RES_COND = np.zeros((N,2))\n",
    "        # MC_RES_COND = np.zeros((N,2))\n",
    "\n",
    "        for zp_id, zp in enumerate(Z):\n",
    "            Yp,rp,wp = firm(Kp,zp)\n",
    "            epsp = draw_eps(self.N)\n",
    "            ypp = self.forward(zp, kp, epsp, training=True)\n",
    "            kpp[:,zp_id].assign(ypp[:,0])\n",
    "            mupp[:,zp_id].assign(ypp[:,1])\n",
    "            cp[:,zp_id].assign(ypp[:,2])\n",
    "            lambdapp[:,zp_id].assign(ypp[:,3])\n",
    "            ee_comp_tmp = tf.pow(c/cp[:,zp_id],γ)\n",
    "            ee_comp[:,zp_id].assign(tf.where(tf.math.is_nan(ee_comp_tmp), 1e6*tf.ones_like(ee_comp_tmp), ee_comp_tmp))\n",
    "            # BUDGET_RES_COND[:,zp_id] = budget_residual(kp, ypp[2], epsp, ypp[0], rp, wp)\n",
    "            # CSK_RES_COND[:,zp_id] = mupp[:,zp_id]*kpp[:,zp_id]\n",
    "            # CSC_RES_COND[:,zp_id] = cp[:,zp_id]*lambdapp[:,zp_id]\n",
    "\n",
    "            Kpp[zp_id].assign(tf.math.reduce_sum(kpp[:,zp_id]))\n",
    "            if Kpp[zp_id]<0:\n",
    "                print(\"Kpp[{0:d}]: NEGATIVE AGGREGATE CAPITAL DESPITE RELU!!\".format(zp_id))\n",
    "            Cp[zp_id].assign(tf.math.reduce_sum(cp[:,zp_id]))\n",
    "            # MC_RES_COND[zp_id] = Cp[zp_id] + Kpp[zp_id] - (1-δ)*Kp - Yp\n",
    "        \n",
    "        EE_RES = tf.pow(\n",
    "            β*(1-δ)*tf.tensordot(ee_comp,tf.transpose(P_z[int(z==z_h),:]), axes=1) - (lambdap - mup),\n",
    "            -1./γ\n",
    "        ) - 1\n",
    "        \n",
    "        MC_RES = C + Kp - (1-δ)*K - Y\n",
    "        return BUDGET_RES, CSK_RES, CSC_RES, MC_RES\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data, batch_size):\n",
    "        z, k, eps = data\n",
    "        ERR = 0\n",
    "        for per_id in range(batch_size):\n",
    "            y = self.forward(z, k, eps, training=False)\n",
    "            BUDGET_RES, CSK_RES, CSC_RES, MC_RES = self.residuals(z, k, eps)\n",
    "            # print(\"BUDGET RESIDUAL: \", BUDGET_RES*BUDGET_RES)\n",
    "            # print(\"CS on K: \", CSK_RES*CSK_RES)\n",
    "            # print(\"CS on C: \", CSC_RES*CSC_RES)\n",
    "            # print(\"MK: \", MC_RES*MC_RES)\n",
    "            # print(\"TOTAL ERROR FORM IS SOURCES: \", tf.math.reduce_mean(BUDGET_RES*BUDGET_RES + CSK_RES*CSK_RES + CSC_RES*CSC_RES))\n",
    "            ERR += (1./batch_size)*tf.math.reduce_mean(BUDGET_RES*BUDGET_RES + CSK_RES*CSK_RES + CSC_RES*CSC_RES) + MC_RES*MC_RES\n",
    "            k = y[:,0]\n",
    "            eps = draw_eps(self.N)\n",
    "            z = draw_z(z)\n",
    "        return ERR, z, k, eps\n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, optimizer, n_epochs=1000, batch_size: int=64):\n",
    "        z = z_h\n",
    "        eps = draw_eps(self.N)\n",
    "        k = self.initialize_k()\n",
    "        metrics = {'mse': []}\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            with tf.GradientTape() as tape:\n",
    "                ERR, z, k, eps = self.train_step([z, k, eps], batch_size)\n",
    "            grads = tape.gradient(ERR, self.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            metrics['mse'].append(ERR.numpy())\n",
    "\n",
    "            # Log every 200 batches.\n",
    "            if epoch % 10 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at epoch %d: %.4f\"\n",
    "                    % (epoch, float(ERR))\n",
    "                )\n",
    "                print(\"Total # time iterations: %d\" % (batch_size*(1+epoch)))\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "lr = 0.00001\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compact network approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slebst/opt/miniconda3/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = num_agents = 500\n",
    "L = N*tf.reduce_mean(E)\n",
    "n_aggr_repr = 8\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "## AGGREGATE REPRESENTATION UNITS\n",
    "# Common network processes distribution-relevant information\n",
    "x_aggr = Input(shape=(N+1, ), name='Distr-In')\n",
    "#xn_aggr = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,)(x_aggr)\n",
    "aggr_1 = Dense(units=4*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer, name='Distr-Dense1')(x_aggr)\n",
    "aggr_2 = Dense(units=4*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer, name='Distr-Dense2')(aggr_1)\n",
    "aggr_3 = Dense(units=2*n_aggr_repr, activation = 'tanh', kernel_initializer=initializer, name='Distr-Dense3')(aggr_2)\n",
    "aggr_4 = Dense(units=n_aggr_repr, activation = 'tanh', kernel_initializer=initializer, name='Distr-Dense4')(aggr_3)\n",
    "\n",
    "## POLICY UNITS\n",
    "# Agent-specific policy units\n",
    "x_idio = Input(shape = (2, ), name='Idio-In')\n",
    "combined = Concatenate(name='Intermediate_Input')([aggr_4, x_idio])\n",
    "interp_c_h_1 = Dense(units=32, input_dim=2+n_aggr_repr, activation = 'tanh', kernel_initializer=initializer, name='Policy-Dense1')(combined)\n",
    "interp_c_h_2 = Dense(units=32, activation = 'tanh', kernel_initializer=initializer, name='Policy-Dense2')(interp_c_h_1)\n",
    "interp_c_h_3 = Dense(units=32, activation = 'relu', kernel_initializer=initializer, name='Policy-Relu1')(interp_c_h_2)\n",
    "policy = Dense(units=4, activation = 'relu', kernel_initializer=initializer, name='Policy-Relu2')(interp_c_h_3)\n",
    "\n",
    "model = DENModel(inputs = [x_aggr,x_idio], outputs= policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"den_model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Distr-In (InputLayer)          [(None, 501)]        0           []                               \n",
      "                                                                                                  \n",
      " Distr-Dense1 (Dense)           (None, 32)           16064       ['Distr-In[0][0]']               \n",
      "                                                                                                  \n",
      " Distr-Dense2 (Dense)           (None, 32)           1056        ['Distr-Dense1[0][0]']           \n",
      "                                                                                                  \n",
      " Distr-Dense3 (Dense)           (None, 16)           528         ['Distr-Dense2[0][0]']           \n",
      "                                                                                                  \n",
      " Distr-Dense4 (Dense)           (None, 8)            136         ['Distr-Dense3[0][0]']           \n",
      "                                                                                                  \n",
      " Idio-In (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " Intermediate_Input (Concatenat  (None, 10)          0           ['Distr-Dense4[0][0]',           \n",
      " e)                                                               'Idio-In[0][0]']                \n",
      "                                                                                                  \n",
      " Policy-Dense1 (Dense)          (None, 32)           352         ['Intermediate_Input[0][0]']     \n",
      "                                                                                                  \n",
      " Policy-Dense2 (Dense)          (None, 32)           1056        ['Policy-Dense1[0][0]']          \n",
      "                                                                                                  \n",
      " Policy-Relu1 (Dense)           (None, 32)           1056        ['Policy-Dense2[0][0]']          \n",
      "                                                                                                  \n",
      " Policy-Relu2 (Dense)           (None, 4)            132         ['Policy-Relu1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,380\n",
      "Trainable params: 20,380\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute-force MC-Distribution-processing neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_aggr_reprb = 8\n",
    "\n",
    "## AGGREGATE REPRESENTATION UNITS\n",
    "## Common network processes distribution-relevant information\n",
    "# x_aggrb = Input(shape = (None,2))\n",
    "# xn_aggrb = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,)(x_aggr)\n",
    "# aggr_1b = Dense(4*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(xn_aggr)\n",
    "# aggr_2b = Dense(4*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_1)\n",
    "# aggr_3b = Dense(2*n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_2)\n",
    "# aggr_4b = Dense(n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(aggr_3)\n",
    "\n",
    "## POLICY UNITS\n",
    "# Agent-specific policy units\n",
    "# x_idiob = Input(shape = (None,2*N))\n",
    "# interp_c_h_1b = Dense(32, input_dim=2*N+n_aggr_reprb, activation = 'tanh', kernel_initializer=initializer)(tf.concat(values=(x_idiob,aggr_4b),axis=1))\n",
    "# interp_c_h_2b = Dense(32, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_1b)\n",
    "# policyb = Dense(2*N, activation = 'tanh', kernel_initializer=initializer)(interp_c_h_2b)\n",
    "\n",
    "# nn2 = DENModel(inputs = tf.concat(values=(x_aggrb,x_idiob)), outputs= policyb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.initialize_k()\n",
    "eps = draw_eps(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.forward(z_h, k, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = model.residuals(z_h, k, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET_RES, CSK_RES, CSC_RES, MC_RES = RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1032903.3>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_mean(BUDGET_RES*BUDGET_RES + CSK_RES*CSK_RES + CSC_RES*CSC_RES) + MC_RES*MC_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERR, z, k, eps = model.train_step([z_h,k,eps], batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1117607.4>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:01<19:25,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at epoch 0: 1089929.2500\n",
      "Total # time iterations: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:11<15:34,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at epoch 10: 42896.0000\n",
      "Total # time iterations: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:20<16:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at epoch 20: 37447.3281\n",
      "Total # time iterations: 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [00:29<14:31,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at epoch 30: 32227.4961\n",
      "Total # time iterations: 496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [00:35<14:59,  1.07it/s]"
     ]
    }
   ],
   "source": [
    "metrics = model.train(optimizer=optimizer, n_epochs=1000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': [1217568.6,\n",
       "  144683.69,\n",
       "  142550.2,\n",
       "  140357.84,\n",
       "  138152.39,\n",
       "  135947.25,\n",
       "  133748.97,\n",
       "  131561.27,\n",
       "  129386.3,\n",
       "  127225.39,\n",
       "  125079.08,\n",
       "  122947.59,\n",
       "  120830.805,\n",
       "  118748.01,\n",
       "  117458.09,\n",
       "  116393.59,\n",
       "  115329.375,\n",
       "  114242.58,\n",
       "  113141.35,\n",
       "  112030.99,\n",
       "  110915.26,\n",
       "  109797.1,\n",
       "  108678.73,\n",
       "  107561.72,\n",
       "  106479.88,\n",
       "  105484.8,\n",
       "  104490.695,\n",
       "  103484.65,\n",
       "  102470.195,\n",
       "  101450.42,\n",
       "  100427.85,\n",
       "  99404.59,\n",
       "  98384.94,\n",
       "  97397.51,\n",
       "  96461.75,\n",
       "  95526.83,\n",
       "  94587.98,\n",
       "  93646.65,\n",
       "  92704.29,\n",
       "  91762.0,\n",
       "  90820.59,\n",
       "  89901.04,\n",
       "  89011.64,\n",
       "  88124.67,\n",
       "  87237.65,\n",
       "  86351.945,\n",
       "  85473.74,\n",
       "  84627.77,\n",
       "  83782.34,\n",
       "  82934.16,\n",
       "  82108.7,\n",
       "  81288.29,\n",
       "  80468.97,\n",
       "  79651.86,\n",
       "  78857.41,\n",
       "  78075.06,\n",
       "  77289.42,\n",
       "  76500.125,\n",
       "  75740.766,\n",
       "  74985.27,\n",
       "  74230.48,\n",
       "  73477.21,\n",
       "  72726.48,\n",
       "  71996.03,\n",
       "  71293.55,\n",
       "  70744.83,\n",
       "  70093.92,\n",
       "  69366.99,\n",
       "  68675.32,\n",
       "  68051.03,\n",
       "  67440.82,\n",
       "  66840.12,\n",
       "  66239.66,\n",
       "  65639.92,\n",
       "  65041.42,\n",
       "  64444.535,\n",
       "  63849.574,\n",
       "  63257.28,\n",
       "  62669.875,\n",
       "  62086.63,\n",
       "  61538.773,\n",
       "  60984.977,\n",
       "  60404.984,\n",
       "  59830.082,\n",
       "  59269.973,\n",
       "  58711.812,\n",
       "  58154.684,\n",
       "  57599.27,\n",
       "  57044.848,\n",
       "  56491.48,\n",
       "  55939.457,\n",
       "  55389.062,\n",
       "  54841.195,\n",
       "  54296.406,\n",
       "  53754.707,\n",
       "  53216.117,\n",
       "  52680.93,\n",
       "  52151.156,\n",
       "  51638.555,\n",
       "  51104.066]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGhCAYAAAC6URSFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApqElEQVR4nO3deXjV9YHv8c/ZsudkIZCQkBBBFoOQlBAQBRFlKVZcardpq0g7tp0njO3Q6b0ySx07vXqnM+PFaaO2o9bW2pYuI23FKhRRVLYIBpCwCAQIkISE7PvZ7h8nBAKICeTw+56c9+t5eE7O7/zO73zD83zx7W87tkAgEBAAAIAh7FYPAAAA4FzECQAAMApxAgAAjEKcAAAAoxAnAADAKMQJAAAwCnECAACM4rR6AAPl9/t18uRJJSYmymazWT0cAADQD4FAQC0tLcrMzJTdful9I2EXJydPnlR2drbVwwAAAJehsrJSo0aNuuQ6YRcniYmJkoK/nNvtHtRtezwerV27VgsWLJDL5RrUbQPoH+YhYK1QzcHm5mZlZ2f3/nf8UsIuTs4cynG73SGJk7i4OLndbv5RBCzCPASsFeo52J9TMjghFgAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYxZI4qaio0Ny5c5WXl6fJkyerra3NimEAAAADOa340AceeEDf//73NXv2bNXX1ys6OtqKYQAAAANd9TjZs2ePXC6XZs+eLUlKTU292kMAAAAGG/BhnY0bN2rx4sXKzMyUzWbT6tWrL1inpKREubm5iomJ0YwZM7Rt27be1z788EMlJCRo8eLFmjp1qh577LEr+gUAAMDQMuA4aWtrU35+vkpKSi76+qpVq7R8+XI98sgj2rFjh/Lz87Vw4UKdOnVKkuT1evX222/rqaee0ubNm7Vu3TqtW7fuyn4LAAAwZAz4sM6iRYu0aNGij3z9iSee0IMPPqilS5dKkp555hmtWbNGzz//vB5++GFlZWVp2rRpys7OliTdfvvtKisr0/z58y+6va6uLnV1dfU+b25uliR5PB55PJ6BDv+SzmxvsLcLoP+Yh4C1QjUHB7K9QT3npLu7W9u3b9eKFSt6l9ntds2bN0+bN2+WJBUVFenUqVNqaGhQUlKSNm7cqK9//esfuc3HH39cjz766AXL165dq7i4uMEcfi/25ADWYx4C1hrsOdje3t7vdQc1Turq6uTz+ZSent5neXp6uvbt2xf8QKdTjz32mG6++WYFAgEtWLBAd9xxx0duc8WKFVq+fHnv8+bmZmVnZ2vBggVyu92DOXx5PB6tW7dO8+fPl8vlGtRtA+gf5iFgrVDNwTNHPvrDkkuJP+7Q0Lmio6Mveqmxy+UK2T9codw2gP5hHgLWGuw5OJBtDepN2NLS0uRwOFRTU9NneU1NjTIyMgbzowAAwBA1qHESFRWlwsJCrV+/vneZ3+/X+vXrNXPmzMH8KAAAMEQN+LBOa2urDh482Pu8oqJCZWVlSk1NVU5OjpYvX64lS5Zo2rRpmj59ulauXKm2trbeq3cAAAAuZcBx8t5772nu3Lm9z8+crLpkyRK98MIL+vznP6/a2lp997vfVXV1tQoKCvTaa69dcJIsAADAxQw4Tm655RYFAoFLrrNs2TItW7bssgcFAAAilyXfSgwAAPBRiBMAAGAU4gQAABglbOKkpKREeXl5KioqsnooAAAghMImToqLi1VeXq7S0lKrhwIAAEIobOIEAABEBuIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGCVs4oTv1gEAIDKETZzw3ToAAESGsIkTAAAQGYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUcImTkpKSpSXl6eioiKrhwIAAEIobOKkuLhY5eXlKi0ttXooAAAghMImTgAAQGQgTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFHCJk5KSkqUl5enoqIiq4cCAABCKGzipLi4WOXl5SotLbV6KAAAIITCJk4AAEBkIE4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYJmzgpKSlRXl6eioqKrB4KAAAIobCJk+LiYpWXl6u0tNTqoQAAgBAKmzgBAACRgTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARgmbOCkpKVFeXp6KioqsHgoAAAihsImT4uJilZeXq7S01OqhAACAEAqbOAEAAJGBOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYJSwiZOSkhLl5eWpqKjI6qEAAIAQCps4KS4uVnl5uUpLS60eCgAACKGwiRMAABAZiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFHCJk5KSkqUl5enoqIiq4cCAABCKGzipLi4WOXl5SotLbV6KAAAIITCJk4AAEBkIE4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBSn1QO4XM++fVix8Ym9z222C9c5f9HF1zm70O/36UCVTU2llYqJcinKYZfLYZfLYet57PnZab/gtSjnhes67Bf5QAAAcElhGycr//Kh7NFxIdiyQ78/sndQtmS3KRguDrtcznNC5kzYOM+GTFRP2DjP+dnV876o86InynmRYOr92a4o53nPz/msM5/t7DMWmxx2m2wXqzcAAK6ysI2TuwsyFR2XoMB5ywPnLQicv0bgoj9Kkrw+n46fOKm0ERny+gPy+ALq9vnlOfPHG5DH51e3zy+v7+zPwdcD8vn7btEfkLq8fnV5/VLXFf26IWc7N6TOiZ3YKIdiXY7ex7hznp/92alYl11xUc4+68VEnb++U7EuB3uUAACXFLZx8v17Jsvtdg/qNj0ej1599bhuv71ALpdrwO/3+QNnQ+ZMvHj7Pu/zms8vj/e85+csO/P8ghDyXhhGH/dZZ18PPveeF1KBgNTtDa4TalFO+0VDJ8Z1fvD0PD83jHp/DoaQO8apxBiXEmOciotysPcHAIaAsI0TEznsNjnswf/Ims7vD8jj74mVnqg5f49Qt9evDo9PnR6f2ruDf8783NHtU4cn+Hh2ubfvOp5z1vP4evdqnYmgpg7PoP5ODrtNCdFOuWOdSowOBktijEvuWKfcMWee9yw7/3nPOtFOO4EDABYjTiKU3W5TtN2haKek6NB/XiAQUKcnGDvt3d4+kdPu8amzJ3LO/TkYN96e91wYSW3dXrV0Bv/4/MHDak0dnp7o6biscboctt49MRcLmpQ4l1Lio5QaH6WUuJ7HeJdS4qLkcnDxGwAMBuIEV4XNZgsekolyKDU+alC3HQgE1OHxqbnDq5ZOj5o7g48tnV419zy29D561dxxkde6vAoEJI8voPq2btW3dQ94HIkxzt5o6Y2YuKgLYia1J2aS46I4/wYALoI4Qdiz2WyKi3IqLsqpjKSYy9qG3x/osycmGDlnIqbneYdXje3BcGnoffSosb1b/oB633v0dHs/xy0lxbqUGheltMRoDU+M1ojEaI1IjNGIM8/dwecpcS4ONwGIGMQJoOBhruDhnMs7Ebq5w6OG9jPR4lFDW7fq27uDj+fFTH1bt5o6PAoEpMZ2jxrbPTpc13bJz3A5bEpLiO6JlhiNcEdreMLZeBmeGK30nmVODi8BCHPECXCFHHabUuKDh2/6y+vzq7EjGDGn27pV29KlUy1dOtXSqdqWruDz5i7Vtnapvq1bHl9AVU2dqmrqlNR0ybFkuGM0MilGmcmxGpkco6zkWGUmnf05KZa9MADMRpwAFnA67EpLiFZaQrTGfcy63V6/6lqD8VLbEzCnms8+r23p7P3Z6w/oRGOHTjR2SEcbLrq9WJdDmcnBeMlMig0+JscoOzVOOalxynDHyM65MAAsRJwAhoty2nsCIvaS6/n8AdW1dulEY4eqGjt1srFDJ5s6go+Nnapq6lBda7c6PD4dqm3TodqLH0qKctqVnRKrnNQ4jR4Wr+zUOI1OjVPOsGC8hMOl8gDCG3ECDBEOu03p7hilu2OknIuv0+nxqbrpTLj0PPbsaamsb9fxhg51e/3nxEvtBdsYkRit0cPilJ0apzFp8Ro7PEFjhido9DDCBcDgIE6ACBLjcig3LV65afEXfd3r86uqqVPH6tt1rL5dR0+3q7K+XUfr23T0dLtaOr0958Z0qfRI38NGdps0KiVOY4fHa8zwhJ5oCcZLWkIU57kA6DfiBEAvp8Ou7NTgXpGbLvJ6Y3t3n3A5VNuqw7VtOlTbqpZOb+9rG/b33eOSGOPUtSMSNCE9URMyEnsfhyVchTsAAgg7xAmAfkvuuXnclFHJfZYHAgHVtnb1hsqZx0O1rTre0KGWTq/eP9ao94819nlfWkK0JmYkanx6oiZmBIMlN5VgASIdcQLgitlstp6bx8XohjHD+rzW6fHpyOk2fVjTqv3VLdpf06L91S06Vt+uutYuvXOwS+8crDtnW9LwaIfWte7SlOxkXZ+ZpEmZSUqKG/g9aACEJ+IEQEjFuByamOHWxAy3FuefXd7W5dWHp1q1v7pZ+6tbtb8m+FjX2qVTnTa9srtar+yu7l1/VEqsrs9M0vVZbk3KStKUrCQOCwFDFHECwBLx0U4VZCerIDu5z/Lqhla98Mc3FJ81QXtrWvXBiWYd67mS6HhDh17bczZYslNjVZCd0rudSZlurhgChgDiBIBRhiVE67rkgG6fM0YuV/BQTlO7R3uqmlR+slkfnGjS7hNNOlTbpsr6DlXWd+hPO09KCt7mP2+kWwXZyfpETooKR6doVEosVwoBYYY4AWC8pDiXbhybphvHpvUua+70aFdlk8oqG/T+sUaVVTbqdFu3dh5v0s7jTfrZ5qOSpAx3jKblpqgoN1XTclM0McPNt0EDhiNOAIQld4xLs8alada4YLAEAgEdb+jQjmMNKqts1I5jjdpzoknVzZ16ZVeVXtlVJUlKiHZq6ugUTc1J1vj0RF07IngDuWgnh4MAUxAnAIYEm83We4+WuwqyJEkd3T6VVTbqvSP1Kj3aoB1HG9Ta5dXGA7XaeODsvVgcdptyUuM0dniCrh0R/HNNWpxyh8UrNZ4byAFXG3ECYMiKjXJo5thhmjk2eHmzzx/QvupmvXekQbuON+lgbasOnWpVa5dXFXVtqqhr01/21vTZRmK0U7lp8Ro9LE7XpMVr9LD44J1v0xK4vBkIEeIEQMRw2G2a1HPflDMCgYBOtXTp4KlWHTzV2nvzuCN17TrZ1KGWLq9295yEe760hCiNSTt7m/5r0xM0Pj1RmUkx7G0BrgBxAiCi2WxnvzDxpmvT+rzW6fGpsr5dR06360hdm46cDu5dOVzbpurmTtW1dquutV7bjtT3eV9C9Nnb9Y9LT9B1I926bqRbqfFRV/NXA8IWcQIAHyHG5dC49ESNS0+84LXWLq8qatt0uC54aOhQbZsO1LSooq5NrV1elVUGryA614jE6N5Qyct06/pMt3KHxcvO1UNAH8QJAFyGhGinJo9K0uRRSX2Wd3v9OnI6GCoHalp1oLpFe6ubdfR0e883OtfqrXNOxo2PcmhSZpKuzwre/TY/O1nXECyIcMQJAAyiKKdd49ODX2Z4rrYur/ZVt2hvVbP2VjWrvKpZ5Seb1dbt07YjfQ8NJcY4lT8qWfnZScofFbyh3PBEbtWPyEGcAMBVEB/tVOHo4F1rz/D6/DpU26bdJ5p673z7wYkmtXR69c7Buj5fiJidGqvCnJSee7Sk6LqR3EwOQxdxAgAWcTrsmpCRqAkZifpM4ShJksfn14GaFu2sbNLOyka9X9mgD0+19t6qf3VZ8Fb9Z24mN73n7rf52cl8rxCGDOIEAAzicth7L3f+4owcScFb9Zcda9SOYw3afrRBZcca1XLezeSinHZNzUnWDWOG6YYxw1RArCCMEScAYDh3jEs3jx+um8cPl3T2ZnKlFfUqPdKgbUfqVdvSpS2H67XlcL2kDxXttKtwdIpu7LkJ3ZRRyXI57Nb+IkA/EScAEGbOvZncAzddo0AgoMN1bdpy+LS2HK7X5kOnVdfapU2HTmvTodOSpLgoh6blpuqGMamacc0wTRmVRKzAWMQJAIQ5m82mscMTNHZ4gr40Y7QCgYAO1bZqc0+cbDl8Wg3tnj6HgeKiHCrKTdWNY4fppmvTOMEWRrEkTnJzc+V2u2W325WSkqINGzZYMQwAGJJsNpuuHZGoa0ck6r6ZufL7A9pX3aKtFae19XC9tlYEY+WtA2fvuZIc59JN16Zpzrjg4aOMpBiLfwtEMsv2nGzatEkJCQlWfTwARAy73aa8zOBdaZfedI38/oAOnGrRuwdPa9PBOm2tqFdju0drdlVpza4qSdKE9ETNnThCt04coak5yXJyCAhXEYd1ACDC2O02Tcxwa2KGW1+ddY28Pr92Hm/UWwfqtPFArXYeb9T+mhbtr2nRM28dkjvGqbkTR2h+XrrmjB+uxBi+jRmhNeAU3rhxoxYvXqzMzEzZbDatXr36gnVKSkqUm5urmJgYzZgxQ9u2bevzus1m05w5c1RUVKSXXnrpsgcPALhyToddhaNTtXz+eK0uvkk7/mm+nvxCge4uyFRynEvNnV79oeyklv3yfU3913Va8vw2/WrbMdW1dlk9dAxRA95z0tbWpvz8fH3lK1/Rpz/96QteX7VqlZYvX65nnnlGM2bM0MqVK7Vw4ULt379fI0aMkCS98847ysrKUlVVlebNm6fJkydrypQpV/7bAACuWEp8lO4qyNJdBVny+QN6/1iD1pXXaF15jQ7XtfWeq/KPL+9WUW6q7pgyUp+8fiS32MegGXCcLFq0SIsWLfrI15944gk9+OCDWrp0qSTpmWee0Zo1a/T888/r4YcfliRlZWVJkkaOHKnbb79dO3bs+Mg46erqUlfX2Tpvbm6WJHk8Hnk8noEO/5LObG+wtwug/5iH5snPSlR+VqL+fv61OlTbpnXlNXq9/JQ+ONmsrRX12lpRr0f+uEfTc1N0x5SRWpiXruQ4Dv2Eq1DNwYFsb1DPOenu7tb27du1YsWK3mV2u13z5s3T5s2bJQX3vPj9fiUmJqq1tVVvvPGGPve5z33kNh9//HE9+uijFyxfu3at4uLiBnP4vdatWxeS7QLoP+ahuXIkPThaOp0u7ay3qey0XUdbbdpS0aAtFQ165I97dF1yQIVpAV2fElAUN6oNS4M9B9vb2/u97qDGSV1dnXw+n9LT0/ssT09P1759+yRJNTU1uueeeyRJPp9PDz74oIqKij5ymytWrNDy5ct7nzc3Nys7O1sLFiyQ2+0ezOHL4/Fo3bp1mj9/vlwuqh+wAvMwvNzX81jZ0K5Xd9folV1V2lfTqg8abPqgQYqPcmj+dSO0OH+kbhyTylU/YSBUc/DMkY/+uOpX64wZM0Y7d+7s9/rR0dGKjr7wOKbL5QrZP1yh3DaA/mEehpcxI5K07LYkLbttvPZXt+iPO0/oD2UndbyhQ6t3Vmn1zioNi4/S7ZNH6u5PZGlqTrJsNm76ZrLBnoMD2dagxklaWpocDodqamr6LK+pqVFGRsZgfhQAwFATMhL1nYyJ+vsFE7TjWIP+UHZSa3ZV6XRbt17cclQvbjmq0cPidHdBlu6dOko5w0JziB7ha1D3r0VFRamwsFDr16/vXeb3+7V+/XrNnDlzMD8KAGA4m82mwtGp+t5d12vrP9ymn31luj79iSzFRTl09HS7nlz/oW7+9w36wk826/fbj6uj22f1kGGIAe85aW1t1cGDB3ufV1RUqKysTKmpqcrJydHy5cu1ZMkSTZs2TdOnT9fKlSvV1tbWe/UOACDyOB12zRk/XHPGD9f3u71au6dGv99xXO8crOv9NuV/+dMe3V2Qpb+anqO8zME9pxDhZcBx8t5772nu3Lm9z8+crLpkyRK98MIL+vznP6/a2lp997vfVXV1tQoKCvTaa69dcJIsACAyxUU5dfcnsnT3J7J0orFD/7P9uH6zvVKV9R29h32m5iTrSzNG61NTRirGxeU+kWbAcXLLLbcoEAhccp1ly5Zp2bJllz0oAEBkyEqO1d/eNk7Fc6/VpkOn9attx/T6nmrtONaoHcca9X9e3asvFGXryzeMVmZyrNXDxVXCd+sAACxnt9s0a1yaZo1L06mWTv2mtFK/3HpMJ5s69dSbh/TjjYe16PoMfXXWNfpETorVw0WIEScAAKOMSIzRslvH6Rtzxuove2v0wqYj2nK4Xq/sqtIru6pUODpFX511jRbkpXPflCGKOAEAGMnpsOuT1we/t6f8ZLN++m6F/lB2UtuPNmj70QaNSonV0puu0eemjeKbkoeYsEnOkpIS5eXlXfJusgCAoSkv061//2y+3nl4rh669VqlxLl0vKFD//pKuW58/A09/upeVTd1Wj1MDJKwiZPi4mKVl5ertLTU6qEAACwyIjFGyxdM0OYVt+mxeyZr7PB4tXR59eONhzX7B2/of/1upw7Xtlo9TFyhsIkTAADOiHE59MUZOVr3d3P03JJpmp6bKo8voN+8d1y3PfGWin+5Q/uq+/9dLjAL55wAAMKW3W7Tbdel67br0rX9aL2e2nBI6/ed0ppdVVqzq0oLJ6Xrm7eN56ZuYYY9JwCAIaFwdKqee6BIrz40W5+aPFI2m/T6nhrd/l9v6xsvbtfeKvakhAviBAAwpORlulXypala+62bdceUYKS8tqdai558W3/zi+3aX91i9RDxMYgTAMCQNC49UT/64lS9fk6k/PmDan3yyY166Ffv60hdm9VDxEcgTgAAQ9r4cyLlU5NHKhCQ/rjzpOY98Zb+8eXdOtXMJcimIU4AABFhfHqiSr40VWsemqW5E4bL6w/opa3HdPO/b9APXtun5k6P1UNED+IEABBRJmUm6adLp2vV127Q1JxkdXr8eurNQ5rzgw16/p0KdXv9Vg8x4hEnAICINGPMMP3+b27UT+4r1Njh8Wpo9+h7r5Rrwf97S6/vqVYgELB6iBGLOAEARCybzaYFkzL0+rdu1mP3TFZaQrSOnG7X11/cri89u5UbuVkkbOKE79YBAISK02HXF2fk6M3v3KLiuWMV5bRr06HTuv3Jt/XPqz9QQ1u31UOMKGETJ3y3DgAg1BKinfrOwolav3yOFl2fIX9AenHLUd3yH2/qxc1H5PVxPsrVEDZxAgDA1ZKdGqenv1yoXz44QxMzEtXU4dE//2GPFv/oXW0/2mD18IY84gQAgI9w49g0vfK3s/S9uyYpKdalvVXNuvfpTXr497vU2M6hnlAhTgAAuASnw677Z+bqjW/P0eemjZIk/bq0UvOeeEur3z/BVT0hQJwAANAPwxKi9YPP5Ou335ipcSMSVNfarW+tKtOXn9vKrfAHGXECAMAAFOWmas1Ds/WdhRMU7bTr3YOntXDlRj395iFOmB0kxAkAAAMU5bSreO61Wvt3N2vWtWnq8vr1b6/t091Pvau9Vdwb5UoRJwAAXKbRw+L14len6z8+m6+kWJc+ONGsO3/0jv5r/YfysBflshEnAABcAZvNps8UjtK65TdrQV66PL6Anlh3QPc+vUkf1rRYPbywRJwAADAIRiTG6Mf3FerJLxQoKdalXceb9KkfvqNn3z4sn58regaCOAEAYJDYbDbdVZCl1791s+aMH65ur1/fX7NXX/jJZh081Wr18MIGcQIAwCDLSIrRC0uL9Ng9kxUf5VDpkQYtXLlRK/5nNzdv6wfiBACAELDZbPrijBy99q2bNT8vXT5/QL/adkzzntio9XtrrB6e0YgTAABCKDs1Tv99/zSt+toNGjs8XnWtXfrqz97T918pV7eXK3ouJmzipKSkRHl5eSoqKrJ6KAAADNiMMcO05qHZWnpTriTp2XcqdO/Tm1TB3WUvEDZxUlxcrPLycpWWllo9FAAALkuMy6FHFk/ST+4rVFKsS7tPNGnRkxv1wrsV8nNFT6+wiRMAAIaKBZMy9OdvztaNY4ep0+PXv/ypXF96dqsq69utHpoRiBMAACyQmRyrX3x1hr531yTFuhzafPi0Fj35tlaVHov4bzomTgAAsIjdbtP9M3P12rdmqyg3Ra1dXv3v3+/Wgz/frtOtXVYPzzLECQAAFhs9LF6//tpMrVg0UVEOu/6yt0affPJtvf1hrdVDswRxAgCAARx2m74+Z6xWF9+kcSMSVNvSpfue26bH/7w34r5EkDgBAMAgeZlu/elvZ+m+G0ZLkn781mF97sebdbwhck6WJU4AADBMjMuhf737ej3z5UK5Y5x6/1ijPvVf7+iNfZFxZ1niBAAAQ33y+gyteWi28kclqanDo6+88J7+4/X9Q/5bjokTAAAMlp0ap99+40YtmRk8zPOjDQf1wE+3qaFt6H6BIHECAIDhopx2PXrX9XryCwWKdTn09od1Wvyjd7T7eJPVQwsJ4gQAgDBxV0GWXi6+UaOHxel4Q4fufXqTXtp6dMjdtI04AQAgjEzMcOuPy2ZpQV66un1+/ePLH2jF/+weUt9wTJwAABBmkmJd+vF9hXp40UTZbdKvSyt1//Nb1dg+NM5DIU4AAAhDNptN35gzVs89UKSEaKe2HK7XPU9tUkVdm9VDu2JhEyclJSXKy8tTUVGR1UMBAMAYcyeM0O//5kZlJceqoq5N9zz1rrYePm31sK5I2MRJcXGxysvLVVpaavVQAAAwyoSMRL1cfKPys5PV2O7Rl5/bqj+UnbB6WJctbOIEAAB8tBGJMVr1tRt0++QMeXwBffPXZXr6zUNheSUPcQIAwBAR43LoR381VX896xpJ0r+9tk+P/qlc/jC7oyxxAgDAEGK32/RPd+Tpnz51nSTphU1H9He/KQurbzYmTgAAGIL+evYYPfmFAjntNv2h7KS+/uJ2dXp8Vg+rX4gTAACGqLsKsvTfS6YpxmXXG/tOaelPS9XW5bV6WB+LOAEAYAibO2GEfv6VGUqIdmrz4dO677mtau70WD2sSyJOAAAY4qZfk6qX/nqGkmJd2nGsUfc9t01NHeYGCnECAEAEyM9O1i8fnKGUOJd2Vjbq/ue2GhsoxAkAABFiUmaSfvngDcFAOd6k+w09xEOcAAAQQa4b6e4TKA88v02thp0kS5wAABBhrhvp1i/OOQflKy+UqqPbnMuMiRMAACLQpMwkvfjV6UqMdmpbRb2+/ovt6vKaESjECQAAEWrKqGT9dGmRYl0ObTxQq4d+9b68BtxJljgBACCCTctN1X/fP01RTrte31Ojf1i9R1Z/VyBxAgBAhJs1Lk1Pf2mqHHabXi6r0p+OWZsHxAkAANBt16Xr/356slwOm0bGWbvrxGnppwMAAGN8dlq2puUkadfmDZaOI2z2nJSUlCgvL09FRUVWDwUAgCFrVEqs1UMInzgpLi5WeXm5SktLrR4KAAAIobCJEwAAEBmIEwAAYBTiBAAAGIU4AQAARiFOAACAUYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEZxWj2AgQoEApKk5ubmQd+2x+NRe3u7mpub5XK5Bn37AD4e8xCwVqjm4Jn/bp/57/ilhF2ctLS0SJKys7MtHgkAABiolpYWJSUlXXIdW6A/CWMQv9+vkydP6tZbb9V7773Xr/cUFRWptLT0Y9drbm5Wdna2Kisr5Xa7r3SoQ0J//+6sYMXYQvGZg7XNK93O5bx/IO9hHl4+5mHoP9OEeXi57x3seRiqORgIBNTS0qLMzEzZ7Zc+qyTs9pzY7XaNGjVKTqez339pDodjQH/BbrebfxR7DPTv7mqyYmyh+MzB2uaVbudy3j+Q9zAPLx/zMPSfacI8vNz3hmoehmIOftwekzPC9oTY4uLikKyLvkz+u7NibKH4zMHa5pVu53Lezzy8Okz+u2MeDt52Lve9Q3Eeht1hnVBqbm5WUlKSmpqajP2/FGCoYx4C1jJhDobtnpNQiI6O1iOPPKLo6GirhwJELOYhYC0T5iB7TgAAgFHYcwIAAIxCnAAAAKMQJwAAwCjECQAAMApxAgAAjEKc9NMrr7yiCRMmaNy4cXr22WetHg4Qke655x6lpKToM5/5jNVDASJSZWWlbrnlFuXl5WnKlCn67W9/G5LP4VLifvB6vcrLy9OGDRuUlJSkwsJCbdq0ScOGDbN6aEBEefPNN9XS0qKf/exn+t3vfmf1cICIU1VVpZqaGhUUFKi6ulqFhYU6cOCA4uPjB/Vz2HPSD9u2bdOkSZOUlZWlhIQELVq0SGvXrrV6WEDEueWWW5SYmGj1MICINXLkSBUUFEiSMjIylJaWpvr6+kH/nIiIk40bN2rx4sXKzMyUzWbT6tWrL1inpKREubm5iomJ0YwZM7Rt27be106ePKmsrKze51lZWTpx4sTVGDowZFzpPARw5QZzHm7fvl0+n0/Z2dmDPs6IiJO2tjbl5+erpKTkoq+vWrVKy5cv1yOPPKIdO3YoPz9fCxcu1KlTp67ySIGhi3kIWG+w5mF9fb3uv/9+/eQnPwnNQAMRRlLg5Zdf7rNs+vTpgeLi4t7nPp8vkJmZGXj88ccDgUAg8O677wbuvvvu3te/+c1vBl566aWrMl5gKLqceXjGhg0bAvfee+/VGCYwpF3uPOzs7AzMnj078POf/zxkY4uIPSeX0t3dre3bt2vevHm9y+x2u+bNm6fNmzdLkqZPn64PPvhAJ06cUGtrq/785z9r4cKFVg0ZGHL6Mw8BhFZ/5mEgENADDzygW2+9Vffdd1/IxhLxcVJXVyefz6f09PQ+y9PT01VdXS1Jcjqd+s///E/NnTtXBQUF+va3v82VOsAg6s88lKR58+bps5/9rF599VWNGjWKcAEGUX/m4bvvvqtVq1Zp9erVKigoUEFBgXbv3j3oY3EO+haHqDvvvFN33nmn1cMAItpf/vIXq4cARLRZs2bJ7/eH/HMifs9JWlqaHA6Hampq+iyvqalRRkaGRaMCIgvzELCeSfMw4uMkKipKhYWFWr9+fe8yv9+v9evXa+bMmRaODIgczEPAeibNw4g4rNPa2qqDBw/2Pq+oqFBZWZlSU1OVk5Oj5cuXa8mSJZo2bZqmT5+ulStXqq2tTUuXLrVw1MDQwjwErBc28zBk1wEZZMOGDQFJF/xZsmRJ7zo//OEPAzk5OYGoqKjA9OnTA1u2bLFuwMAQxDwErBcu85Dv1gEAAEaJ+HNOAACAWYgTAABgFOIEAAAYhTgBAABGIU4AAIBRiBMAAGAU4gQAABiFOAEAAEYhTgAAgFGIEwAAYBTiBAAAGIU4AQAARvn/j0nQcAp6BTUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig, ax = plt.subplots(1,1)\n",
    "plt.plot(\n",
    "    range(100),\n",
    "    metrics['mse'],\n",
    ")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dynamic Programming & DL",
   "language": "python",
   "name": "dynprog_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
